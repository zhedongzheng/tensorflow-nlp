{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 4533\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shuffled\n",
      "Epoch 1/1 | Step 0/1142 | train_loss: 71.7411 | train_acc: 0.1728 | lr: 0.0050\n",
      "Epoch 1/1 | Step 50/1142 | train_loss: 16.9390 | train_acc: 0.8622 | lr: 0.0045\n",
      "Epoch 1/1 | Step 100/1142 | train_loss: 11.2224 | train_acc: 0.9013 | lr: 0.0041\n",
      "Epoch 1/1 | Step 150/1142 | train_loss: 8.8146 | train_acc: 0.9247 | lr: 0.0037\n",
      "Epoch 1/1 | Step 200/1142 | train_loss: 8.6291 | train_acc: 0.9283 | lr: 0.0033\n",
      "Epoch 1/1 | Step 250/1142 | train_loss: 7.8113 | train_acc: 0.9281 | lr: 0.0030\n",
      "Epoch 1/1 | Step 300/1142 | train_loss: 6.5333 | train_acc: 0.9413 | lr: 0.0027\n",
      "Epoch 1/1 | Step 350/1142 | train_loss: 6.1794 | train_acc: 0.9430 | lr: 0.0025\n",
      "Epoch 1/1 | Step 400/1142 | train_loss: 4.7302 | train_acc: 0.9575 | lr: 0.0022\n",
      "Epoch 1/1 | Step 450/1142 | train_loss: 4.7968 | train_acc: 0.9577 | lr: 0.0020\n",
      "Epoch 1/1 | Step 500/1142 | train_loss: 4.7933 | train_acc: 0.9577 | lr: 0.0018\n",
      "Epoch 1/1 | Step 550/1142 | train_loss: 4.3943 | train_acc: 0.9598 | lr: 0.0016\n",
      "Epoch 1/1 | Step 600/1142 | train_loss: 4.4817 | train_acc: 0.9556 | lr: 0.0015\n",
      "Epoch 1/1 | Step 650/1142 | train_loss: 3.9582 | train_acc: 0.9658 | lr: 0.0013\n",
      "Epoch 1/1 | Step 700/1142 | train_loss: 4.2149 | train_acc: 0.9569 | lr: 0.0012\n",
      "Epoch 1/1 | Step 750/1142 | train_loss: 4.0131 | train_acc: 0.9616 | lr: 0.0011\n",
      "Epoch 1/1 | Step 800/1142 | train_loss: 3.8304 | train_acc: 0.9611 | lr: 0.0010\n",
      "Epoch 1/1 | Step 850/1142 | train_loss: 3.1596 | train_acc: 0.9681 | lr: 0.0009\n",
      "Epoch 1/1 | Step 900/1142 | train_loss: 3.1227 | train_acc: 0.9692 | lr: 0.0008\n",
      "Epoch 1/1 | Step 950/1142 | train_loss: 3.4008 | train_acc: 0.9684 | lr: 0.0007\n",
      "Epoch 1/1 | Step 1000/1142 | train_loss: 3.3911 | train_acc: 0.9656 | lr: 0.0007\n",
      "Epoch 1/1 | Step 1050/1142 | train_loss: 3.0856 | train_acc: 0.9681 | lr: 0.0006\n",
      "Epoch 1/1 | Step 1100/1142 | train_loss: 2.7325 | train_acc: 0.9706 | lr: 0.0005\n",
      "Epoch 1/1 | train_loss: 2.1710 | train_acc: 0.9777 | lr: 0.0005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.94      0.96      0.95    116058\n",
      "          M       0.88      0.84      0.86     25425\n",
      "          E       0.94      0.96      0.95    116057\n",
      "          S       0.95      0.92      0.94    106810\n",
      "\n",
      "avg / total       0.94      0.94      0.94    364350\n",
      "\n",
      "我 来到 大学 读书 ， 希望 学 到 知识 \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import chseg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from cnn_seq_label import Tagger\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "SEQ_LEN = 50\n",
    "N_CLASS = 4 # B: 0, M: 1, E: 2, S: 3\n",
    "N_EPOCH = 1\n",
    "BATCH_SIZE = 128\n",
    "sample = '我来到大学读书，希望学到知识'\n",
    "py = int(sys.version[0])\n",
    "\n",
    "\n",
    "def to_train_seq(*args):\n",
    "    data = []\n",
    "    for x in args:\n",
    "        data.append(iter_seq(x))\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_test_seq(*args):\n",
    "    data = []\n",
    "    for x in args:\n",
    "        x = x[: (len(x) - len(x) % SEQ_LEN)]\n",
    "        data.append(np.reshape(x, [-1, SEQ_LEN]))\n",
    "    return data\n",
    "\n",
    "\n",
    "def iter_seq(x, text_iter_step=10):\n",
    "    return np.array([x[i : i+SEQ_LEN] for i in range(0, len(x)-SEQ_LEN, text_iter_step)])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x_train, y_train, x_test, y_test, vocab_size, word2idx, idx2word = chseg.load_data()\n",
    "    X_train, Y_train = to_train_seq(x_train, y_train)\n",
    "    X_test, Y_test = to_test_seq(x_test, y_test)\n",
    "    print('Vocab size: %d' % vocab_size)\n",
    "\n",
    "    clf = Tagger(vocab_size, N_CLASS, SEQ_LEN)\n",
    "    clf.fit(X_train, Y_train, n_epoch=N_EPOCH, batch_size=BATCH_SIZE)\n",
    "\n",
    "    y_pred = clf.predict(X_test, batch_size=BATCH_SIZE)\n",
    "    print(classification_report(Y_test.ravel(), y_pred.ravel(), target_names=['B', 'M', 'E', 'S']))\n",
    "\n",
    "    chars = list(sample) if py == 3 else list(sample.decode('utf-8'))\n",
    "    _test = [word2idx[w] for w in sample] + [0] * (SEQ_LEN-len(sample))\n",
    "    labels = clf.infer(_test, len(sample))\n",
    "    labels = labels[:len(sample)]\n",
    "    res = ''\n",
    "    for i, l in enumerate(labels):\n",
    "        c = sample[i] if py == 3 else sample.decode('utf-8')[i]\n",
    "        if l == 2 or l == 3:\n",
    "            c += ' '\n",
    "        res += c\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
