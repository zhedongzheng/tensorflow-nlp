{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 4533\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shuffled\n",
      "Epoch 1/1 | Step 0/1142 | train_loss: 100.7424 | train_acc: 0.2237 | lr: 0.0050\n",
      "Epoch 1/1 | Step 50/1142 | train_loss: 23.0107 | train_acc: 0.8127 | lr: 0.0045\n",
      "Epoch 1/1 | Step 100/1142 | train_loss: 17.9541 | train_acc: 0.8562 | lr: 0.0041\n",
      "Epoch 1/1 | Step 150/1142 | train_loss: 12.8941 | train_acc: 0.8913 | lr: 0.0037\n",
      "Epoch 1/1 | Step 200/1142 | train_loss: 10.6346 | train_acc: 0.9172 | lr: 0.0033\n",
      "Epoch 1/1 | Step 250/1142 | train_loss: 9.7816 | train_acc: 0.9166 | lr: 0.0030\n",
      "Epoch 1/1 | Step 300/1142 | train_loss: 9.0972 | train_acc: 0.9252 | lr: 0.0027\n",
      "Epoch 1/1 | Step 350/1142 | train_loss: 8.2243 | train_acc: 0.9298 | lr: 0.0025\n",
      "Epoch 1/1 | Step 400/1142 | train_loss: 6.7713 | train_acc: 0.9439 | lr: 0.0022\n",
      "Epoch 1/1 | Step 450/1142 | train_loss: 6.7307 | train_acc: 0.9389 | lr: 0.0020\n",
      "Epoch 1/1 | Step 500/1142 | train_loss: 6.2553 | train_acc: 0.9448 | lr: 0.0018\n",
      "Epoch 1/1 | Step 550/1142 | train_loss: 6.0360 | train_acc: 0.9458 | lr: 0.0016\n",
      "Epoch 1/1 | Step 600/1142 | train_loss: 5.9359 | train_acc: 0.9450 | lr: 0.0015\n",
      "Epoch 1/1 | Step 650/1142 | train_loss: 5.4142 | train_acc: 0.9520 | lr: 0.0013\n",
      "Epoch 1/1 | Step 700/1142 | train_loss: 4.5742 | train_acc: 0.9597 | lr: 0.0012\n",
      "Epoch 1/1 | Step 750/1142 | train_loss: 5.1142 | train_acc: 0.9530 | lr: 0.0011\n",
      "Epoch 1/1 | Step 800/1142 | train_loss: 4.7672 | train_acc: 0.9555 | lr: 0.0010\n",
      "Epoch 1/1 | Step 850/1142 | train_loss: 4.0183 | train_acc: 0.9648 | lr: 0.0009\n",
      "Epoch 1/1 | Step 900/1142 | train_loss: 4.5935 | train_acc: 0.9530 | lr: 0.0008\n",
      "Epoch 1/1 | Step 950/1142 | train_loss: 4.0702 | train_acc: 0.9656 | lr: 0.0007\n",
      "Epoch 1/1 | Step 1000/1142 | train_loss: 3.7511 | train_acc: 0.9688 | lr: 0.0007\n",
      "Epoch 1/1 | Step 1050/1142 | train_loss: 3.8945 | train_acc: 0.9650 | lr: 0.0006\n",
      "Epoch 1/1 | Step 1100/1142 | train_loss: 3.7967 | train_acc: 0.9664 | lr: 0.0005\n",
      "Epoch 1/1 | train_loss: 3.1508 | train_acc: 0.9800 | lr: 0.0005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.93      0.95      0.94    116058\n",
      "          M       0.88      0.81      0.84     25425\n",
      "          E       0.94      0.95      0.94    116057\n",
      "          S       0.94      0.92      0.93    106810\n",
      "\n",
      "avg / total       0.93      0.93      0.93    364350\n",
      "\n",
      "我 来到 大学 读书 ， 希望 学 到 知识 \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import chseg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from multihead_attn_clf import Tagger\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "SEQ_LEN = 50\n",
    "N_CLASS = 4 # B: 0, M: 1, E: 2, S: 3\n",
    "N_EPOCH = 1\n",
    "BATCH_SIZE = 128\n",
    "sample = '我来到大学读书，希望学到知识'\n",
    "py = int(sys.version[0])\n",
    "\n",
    "\n",
    "def to_train_seq(*args):\n",
    "    data = []\n",
    "    for x in args:\n",
    "        data.append(iter_seq(x))\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_test_seq(*args):\n",
    "    data = []\n",
    "    for x in args:\n",
    "        x = x[: (len(x) - len(x) % SEQ_LEN)]\n",
    "        data.append(np.reshape(x, [-1, SEQ_LEN]))\n",
    "    return data\n",
    "\n",
    "\n",
    "def iter_seq(x, text_iter_step=10):\n",
    "    return np.array([x[i : i+SEQ_LEN] for i in range(0, len(x)-SEQ_LEN, text_iter_step)])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x_train, y_train, x_test, y_test, vocab_size, word2idx, idx2word = chseg.load_data()\n",
    "    X_train, Y_train = to_train_seq(x_train, y_train)\n",
    "    X_test, Y_test = to_test_seq(x_test, y_test)\n",
    "    print('Vocab size: %d' % vocab_size)\n",
    "\n",
    "    clf = Tagger(vocab_size, N_CLASS, SEQ_LEN)\n",
    "    clf.fit(X_train, Y_train, n_epoch=N_EPOCH, batch_size=BATCH_SIZE)\n",
    "\n",
    "    y_pred = clf.predict(X_test, batch_size=BATCH_SIZE)\n",
    "    print(classification_report(Y_test.ravel(), y_pred.ravel(), target_names=['B', 'M', 'E', 'S']))\n",
    "\n",
    "    chars = list(sample) if py == 3 else list(sample.decode('utf-8'))\n",
    "    _test = [word2idx[w] for w in sample] + [0] * (SEQ_LEN-len(sample))\n",
    "    labels = clf.infer(_test, len(sample))\n",
    "    labels = labels[:len(sample)]\n",
    "    res = ''\n",
    "    for i, l in enumerate(labels):\n",
    "        c = sample[i] if py == 3 else sample.decode('utf-8')[i]\n",
    "        if l == 2 or l == 3:\n",
    "            c += ' '\n",
    "        res += c\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
