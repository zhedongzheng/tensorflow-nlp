{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 4533\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shuffled\n",
      "Epoch 1/1 | Step 0/1142 | train_loss: 100.8862 | train_acc: 0.2036 | lr: 0.0050\n",
      "Epoch 1/1 | Step 50/1142 | train_loss: 22.1137 | train_acc: 0.8228 | lr: 0.0045\n",
      "Epoch 1/1 | Step 100/1142 | train_loss: 16.3935 | train_acc: 0.8642 | lr: 0.0041\n",
      "Epoch 1/1 | Step 150/1142 | train_loss: 13.1400 | train_acc: 0.8880 | lr: 0.0037\n",
      "Epoch 1/1 | Step 200/1142 | train_loss: 11.0736 | train_acc: 0.9019 | lr: 0.0033\n",
      "Epoch 1/1 | Step 250/1142 | train_loss: 9.8716 | train_acc: 0.9137 | lr: 0.0030\n",
      "Epoch 1/1 | Step 300/1142 | train_loss: 8.6743 | train_acc: 0.9206 | lr: 0.0027\n",
      "Epoch 1/1 | Step 350/1142 | train_loss: 8.0453 | train_acc: 0.9298 | lr: 0.0025\n",
      "Epoch 1/1 | Step 400/1142 | train_loss: 7.0999 | train_acc: 0.9406 | lr: 0.0022\n",
      "Epoch 1/1 | Step 450/1142 | train_loss: 6.1951 | train_acc: 0.9447 | lr: 0.0020\n",
      "Epoch 1/1 | Step 500/1142 | train_loss: 6.3411 | train_acc: 0.9414 | lr: 0.0018\n",
      "Epoch 1/1 | Step 550/1142 | train_loss: 5.8999 | train_acc: 0.9475 | lr: 0.0016\n",
      "Epoch 1/1 | Step 600/1142 | train_loss: 5.5607 | train_acc: 0.9480 | lr: 0.0015\n",
      "Epoch 1/1 | Step 650/1142 | train_loss: 5.2453 | train_acc: 0.9523 | lr: 0.0013\n",
      "Epoch 1/1 | Step 700/1142 | train_loss: 4.3188 | train_acc: 0.9613 | lr: 0.0012\n",
      "Epoch 1/1 | Step 750/1142 | train_loss: 4.1683 | train_acc: 0.9639 | lr: 0.0011\n",
      "Epoch 1/1 | Step 800/1142 | train_loss: 5.4505 | train_acc: 0.9456 | lr: 0.0010\n",
      "Epoch 1/1 | Step 850/1142 | train_loss: 4.5415 | train_acc: 0.9597 | lr: 0.0009\n",
      "Epoch 1/1 | Step 900/1142 | train_loss: 4.1612 | train_acc: 0.9591 | lr: 0.0008\n",
      "Epoch 1/1 | Step 950/1142 | train_loss: 3.7262 | train_acc: 0.9645 | lr: 0.0007\n",
      "Epoch 1/1 | Step 1000/1142 | train_loss: 3.8214 | train_acc: 0.9644 | lr: 0.0007\n",
      "Epoch 1/1 | Step 1050/1142 | train_loss: 4.0282 | train_acc: 0.9620 | lr: 0.0006\n",
      "Epoch 1/1 | Step 1100/1142 | train_loss: 4.2526 | train_acc: 0.9595 | lr: 0.0005\n",
      "Epoch 1/1 | train_loss: 4.7959 | train_acc: 0.9523 | lr: 0.0005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.94      0.95      0.94    116058\n",
      "          M       0.85      0.83      0.84     25425\n",
      "          E       0.94      0.95      0.94    116057\n",
      "          S       0.94      0.92      0.93    106810\n",
      "\n",
      "avg / total       0.93      0.93      0.93    364350\n",
      "\n",
      "我 来到 大学 读书 ， 希望 学 到 知识 \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import chseg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from multihead_attn_clf import Tagger\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "SEQ_LEN = 50\n",
    "N_CLASS = 4 # B: 0, M: 1, E: 2, S: 3\n",
    "N_EPOCH = 1\n",
    "BATCH_SIZE = 128\n",
    "sample = '我来到大学读书，希望学到知识'\n",
    "py = int(sys.version[0])\n",
    "\n",
    "\n",
    "def to_train_seq(*args):\n",
    "    data = []\n",
    "    for x in args:\n",
    "        data.append(iter_seq(x))\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_test_seq(*args):\n",
    "    data = []\n",
    "    for x in args:\n",
    "        x = x[: (len(x) - len(x) % SEQ_LEN)]\n",
    "        data.append(np.reshape(x, [-1, SEQ_LEN]))\n",
    "    return data\n",
    "\n",
    "\n",
    "def iter_seq(x, text_iter_step=10):\n",
    "    return np.array([x[i : i+SEQ_LEN] for i in range(0, len(x)-SEQ_LEN, text_iter_step)])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x_train, y_train, x_test, y_test, vocab_size, word2idx, idx2word = chseg.load_data()\n",
    "    X_train, Y_train = to_train_seq(x_train, y_train)\n",
    "    X_test, Y_test = to_test_seq(x_test, y_test)\n",
    "    print('Vocab size: %d' % vocab_size)\n",
    "\n",
    "    clf = Tagger(vocab_size, N_CLASS, SEQ_LEN)\n",
    "    clf.fit(X_train, Y_train, n_epoch=N_EPOCH, batch_size=BATCH_SIZE)\n",
    "\n",
    "    y_pred = clf.predict(X_test, batch_size=BATCH_SIZE)\n",
    "    print(classification_report(Y_test.ravel(), y_pred.ravel(), target_names=['B', 'M', 'E', 'S']))\n",
    "\n",
    "    chars = list(sample) if py == 3 else list(sample.decode('utf-8'))\n",
    "    _test = [word2idx[w] for w in sample] + [0] * (SEQ_LEN-len(sample))\n",
    "    labels = clf.infer(_test, len(sample))\n",
    "    labels = labels[:len(sample)]\n",
    "    res = ''\n",
    "    for i, l in enumerate(labels):\n",
    "        c = sample[i] if py == 3 else sample.decode('utf-8')[i]\n",
    "        if l == 2 or l == 3:\n",
    "            c += ' '\n",
    "        res += c\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
